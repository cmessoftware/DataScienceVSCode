{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image in a markdown cell](https://cursos.utnba.centrodeelearning.com/pluginfile.php/1/theme_space/customlogo/1738330016/Logo%20UTN%20Horizontal.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Diplomado de Ciencia de Datos y AnÃ¡lisis Avanzado**\n",
    "# **Unidad 5: Modelado Predictivo I**: RegresiÃ³n y ClasificaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyecto de Competencia Kaggle: PredicciÃ³n de Abandono de Clientes**\n",
    "\n",
    "## **Curso:** Diplomado en Ciencia de Datos\n",
    "\n",
    "# **Nombres de los Miembros del Equipo:**\n",
    "### *   [Nombre Completo del Miembro 1]\n",
    "### *   [Nombre Completo del Miembro 2]\n",
    "### *   [Nombre Completo del Miembro 3]\n",
    "\n",
    "# **Objetivo:**\n",
    "## El objetivo de este proyecto es construir y evaluar varios modelos de clasificaciÃ³n para predecir si un cliente de una compaÃ±Ã­a de telecomunicaciones abandonarÃ¡ o no el servicio (churn). El rendimiento final del mejor modelo se medirÃ¡ en la competencia de Kaggle a travÃ©s de la **mÃ©trica ROC AUC**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Enlace para unirse a la competencia**\n",
    "### **USE EL ENLACE PARA UNIRSE POR EQUIPO, NO DE MANERA INDIVIDUAL**\n",
    "\n",
    "https://www.kaggle.com/t/57b70c381e4d451b8ae38e164b91a2aa\n",
    "\n",
    "\n",
    "### **Por favor siga las indicaciones que se suministran en la plataforma**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. **ConfiguraciÃ³n Inicial e ImportaciÃ³n de LibrerÃ­as**\n",
    "\n",
    "## En esta secciÃ³n, importaremos todas las librerÃ­as necesarias para el proyecto. Es una buena prÃ¡ctica tener todas las importaciones en la primera celda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones bÃ¡sicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Importar mÃ³dulos del proyecto (si existen)\n",
    "try:\n",
    "    import data_loader\n",
    "    import dataset_splitter\n",
    "    import eda\n",
    "    import models\n",
    "    import metrics\n",
    "    print(\"âœ… MÃ³dulos del proyecto importados correctamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Algunos mÃ³dulos del proyecto no estÃ¡n disponibles: {e}\")\n",
    "    print(\"ðŸ’¡ Puedes trabajar directamente en el notebook por ahora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **1. Carga de Datos**\n",
    "\n",
    "## Cargaremos los datasets proporcionados para la competencia: `train.csv`, `test.csv` y `sample_submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    sample_submission_df = pd.read_csv('sample_submission.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"AsegÃºrate de que los archivos .csv de la competencia estÃ©n en el mismo directorio que este cuaderno.\")\n",
    "    print(\"Si usas Colab, puedes subir los archivos al entorno de ejecuciÃ³n.\")\n",
    "    # Crear datos de ejemplo para desarrollo\n",
    "    print(\"ðŸ“ Creando datos de ejemplo para desarrollo...\")\n",
    "    \n",
    "    # Simular datos de entrenamiento\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    train_df = pd.DataFrame({\n",
    "        'customerID': [f'C{i:04d}' for i in range(n_samples)],\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'tenure': np.random.randint(0, 72, n_samples),\n",
    "        'MonthlyCharges': np.random.uniform(20, 120, n_samples),\n",
    "        'TotalCharges': np.random.uniform(100, 8000, n_samples),\n",
    "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples),\n",
    "        'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples),\n",
    "        'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples),\n",
    "        'Churn': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "    })\n",
    "    \n",
    "    # Simular datos de prueba\n",
    "    test_df = train_df.drop('Churn', axis=1).sample(200).reset_index(drop=True)\n",
    "    test_df['customerID'] = [f'T{i:04d}' for i in range(len(test_df))]\n",
    "    \n",
    "    # Simular archivo de submission\n",
    "    sample_submission_df = pd.DataFrame({\n",
    "        'customerID': test_df['customerID'],\n",
    "        'Churn': 0.5\n",
    "    })\n",
    "\n",
    "print(\"Forma del dataset de entrenamiento:\", train_df.shape)\n",
    "print(\"Forma del dataset de prueba:\", test_df.shape)\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del dataset de entrenamiento:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del dataset de prueba:\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2**. AnÃ¡lisis Exploratorio de Datos (EDA)**\n",
    "\n",
    "## En esta fase, exploraremos el dataset de entrenamiento para entender mejor nuestros datos, encontrar patrones, identificar valores faltantes y visualizar relaciones entre las caracterÃ­sticas y la variable objetivo (`Churn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo: conocer distribuciÃ³n de datos, target, tipos de columnas.\n",
    "\n",
    "Variables como Contract, InternetService, PaymentMethod requieren OneHotEncoding o LabelEncoding. #TODO: Verificar.\n",
    "\n",
    "Target Churn: dataset mÃ¡s desbalanceado (~20% churn). #Verificar el desbalanceo.\n",
    "\n",
    "## DescripciÃ³n de parÃ¡metros\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InformaciÃ³n general del dataset\n",
    "print(\"ðŸ“Š INFORMACIÃ“N GENERAL DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimensiones: {train_df.shape}\")\n",
    "print(f\"Columnas: {list(train_df.columns)}\")\n",
    "print(\"\\nðŸ“‹ Tipos de datos:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "# InformaciÃ³n sobre valores faltantes\n",
    "print(\"\\nðŸ” VALORES FALTANTES:\")\n",
    "print(\"=\" * 30)\n",
    "missing_values = train_df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"âœ… No hay valores faltantes\")\n",
    "\n",
    "# DistribuciÃ³n de la variable objetivo\n",
    "print(\"\\nðŸŽ¯ DISTRIBUCIÃ“N DE LA VARIABLE OBJETIVO (Churn):\")\n",
    "print(\"=\" * 50)\n",
    "churn_counts = train_df['Churn'].value_counts()\n",
    "churn_pct = train_df['Churn'].value_counts(normalize=True) * 100\n",
    "print(f\"No Churn (0): {churn_counts[0]} ({churn_pct[0]:.1f}%)\")\n",
    "print(f\"Churn (1): {churn_counts[1]} ({churn_pct[1]:.1f}%)\")\n",
    "\n",
    "# VisualizaciÃ³n de la distribuciÃ³n del target\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "train_df['Churn'].value_counts().plot(kind='bar', color=['lightblue', 'salmon'])\n",
    "plt.title('DistribuciÃ³n de Churn')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "train_df['Churn'].value_counts(normalize=True).plot(kind='pie', autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
    "plt.title('ProporciÃ³n de Churn')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Preprocesamiento de Datos**\n",
    "\n",
    "## Prepararemos los datos para que puedan ser utilizados por los modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos usando los modelos creados\n",
    "from TP5.models import ChurnPredictor\n",
    "\n",
    "# Inicializar el predictor\n",
    "predictor = ChurnPredictor(random_state=42)\n",
    "\n",
    "# Crear el preprocesador\n",
    "preprocessor = predictor.create_preprocessor(X_train)\n",
    "\n",
    "print(\"âœ… Preprocesador configurado exitosamente\")\n",
    "print(f\"ðŸ“Š CaracterÃ­sticas a procesar: {X_train.shape[1]}\")\n",
    "\n",
    "# Mostrar informaciÃ³n del preprocesador\n",
    "print(\"\\nðŸ”§ ConfiguraciÃ³n del preprocesador:\")\n",
    "print(f\"   - CaracterÃ­sticas numÃ©ricas: {len(X_train.select_dtypes(include=['int64', 'float64']).columns)}\")\n",
    "print(f\"   - CaracterÃ­sticas categÃ³ricas: {len(X_train.select_dtypes(include=['object']).columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Modelado y EvaluaciÃ³n**\n",
    "\n",
    "## Ahora entrenaremos y evaluaremos los tres modelos requeridos:\n",
    "## RegresiÃ³n LogÃ­stica, k-NN y Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de modelos usando ChurnPredictor\n",
    "print(\"ðŸ¤– Iniciando entrenamiento de modelos...\")\n",
    "\n",
    "# Crear los modelos\n",
    "models = predictor.create_models()\n",
    "\n",
    "# Entrenar todos los modelos\n",
    "predictor.train_models(X_train, y_train)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Entrenamiento completado para todos los modelos:\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"   âœ… {model_name}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Modelos entrenados con {len(X_train):,} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **5. SelecciÃ³n de Modelo y GeneraciÃ³n de Submission para Kaggle**\n",
    "\n",
    "## Basado en tus resultados de validaciÃ³n, elige el mejor modelo . Luego, re-entrÃ©nalo usando **todos los datos de `train.csv`** y Ãºsalo para hacer predicciones sobre `test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EvaluaciÃ³n de modelos\n",
    "from TP5.metrics import MetricsCalculator\n",
    "\n",
    "print(\"ðŸ“Š Evaluando modelos...\")\n",
    "\n",
    "# Evaluar con el predictor\n",
    "results = predictor.evaluate_models(X_val, y_val)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model_name, best_model = predictor.get_best_model('ROC_AUC')\n",
    "\n",
    "# Generar reporte completo\n",
    "predictor.generate_model_report(X_val, y_val)\n",
    "\n",
    "# Usar el calculador de mÃ©tricas para anÃ¡lisis detallado del mejor modelo\n",
    "calc = MetricsCalculator()\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred = best_model.predict(X_val)\n",
    "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Reporte detallado\n",
    "detailed_report = calc.generate_detailed_report(\n",
    "    y_val, y_pred, y_pred_proba,\n",
    "    class_names=['No Churn', 'Churn'],\n",
    "    model_name=best_model_name\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ† Mejor modelo seleccionado: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **6. Conclusiones (Opcional pero Recomendado)**\n",
    "\n",
    "## Escribe un breve resumen de tus hallazgos.\n",
    "* ## Â¿QuÃ© modelo funcionÃ³ mejor y por quÃ© crees que fue asÃ­?\n",
    "* ## Â¿CuÃ¡les fueron las caracterÃ­sticas mÃ¡s importantes o los descubrimientos mÃ¡s interesantes del EDA?\n",
    "* ## Â¿QuÃ© desafÃ­os encontraron y cÃ³mo los resolvieron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FunciÃ³n para generar el archivo de submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_submission_file(final_model, X_train_full, y_train_full, X_test_full, customer_ids, filename=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Entrena el modelo final con todos los datos de entrenamiento, genera predicciones\n",
    "    de probabilidad en el conjunto de prueba y guarda el archivo de submission.\n",
    "\n",
    "    Args:\n",
    "        final_model: El modelo y preprocesamiento elegido.\n",
    "        X_train_full (DataFrame): El DataFrame completo de caracterÃ­sticas de entrenamiento.\n",
    "        y_train_full (Series): La Serie completa del objetivo de entrenamiento.\n",
    "        X_test_full (DataFrame): El DataFrame de caracterÃ­sticas de prueba.\n",
    "        customer_ids (Series): La Serie de customerID para el archivo de submission.\n",
    "        filename (str): El nombre del archivo CSV de salida.\n",
    "    \"\"\"\n",
    "    print(\"Entrenando el modelo final con todos los datos de entrenamiento...\")\n",
    "    final_model.fit(X_train_full, y_train_full)\n",
    "    print(\"Modelo final entrenado.\")\n",
    "\n",
    "    print(\"Generando predicciones de probabilidad sobre el conjunto de prueba...\")\n",
    "    test_probabilities = final_model.predict_proba(X_test_full)[:, 1]\n",
    "\n",
    "    print(f\"Creando el archivo de submission '{filename}'...\")\n",
    "    submission_df = pd.DataFrame({\n",
    "        'customerID': customer_ids,\n",
    "        'Churn': test_probabilities\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Archivo '{filename}' generado exitosamente.\")\n",
    "    print(\"Primeras 5 filas del archivo de submission:\")\n",
    "    display(submission_df.head())\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta y ejecuta cuando tengas el modelo final listo\n",
    "# submission_final = generar_submission_file(\n",
    "#     final_model=mejor_modelo,\n",
    "#     X_train_full=X,\n",
    "#     y_train_full=y,\n",
    "#     X_test_full=X_test_final,\n",
    "#     customer_ids=test_customer_ids,\n",
    "#     filename=\"mi_submission_final.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NGbiFnclWCL"
   },
   "source": [
    "![Image in a markdown cell](https://cursos.utnba.centrodeelearning.com/pluginfile.php/1/theme_space/customlogo/1738330016/Logo%20UTN%20Horizontal.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuprUYNItamA"
   },
   "source": [
    "# **Diplomado de Ciencia de Datos y AnÃ¡lisis Avanzado**\n",
    "# **Unidad 5: Modelado Predictivo I**: RegresiÃ³n y ClasificaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwq174zItdhi"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hA-KQxHlV2a"
   },
   "source": [
    "# **Proyecto de Competencia Kaggle: PredicciÃ³n de Abandono de Clientes**\n",
    "\n",
    "## **Curso:** Diplomado en Ciencia de Datos\n",
    "\n",
    "# **Nombres de los Miembros del Equipo:**\n",
    "### *   [Nombre Completo del Miembro 1]\n",
    "### *   [Nombre Completo del Miembro 2]\n",
    "### *   [Nombre Completo del Miembro 3]\n",
    "\n",
    "# **Objetivo:**\n",
    "## El objetivo de este proyecto es construir y evaluar varios modelos de clasificaciÃ³n para predecir si un cliente de una compaÃ±Ã­a de telecomunicaciones abandonarÃ¡ o no el servicio (churn). El rendimiento final del mejor modelo se medirÃ¡ en la competencia de Kaggle a travÃ©s de la **mÃ©trica ROC AUC**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqk8OzCZrz9A"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4oEVvfDr2BJ"
   },
   "source": [
    "# **Enlace para unirse a la competencia**\n",
    "### **USE EL ENLACE PARA UNIRSE POR EQUIPO, NO DE MANERA INDIVIDUAL**\n",
    "\n",
    "https://www.kaggle.com/t/57b70c381e4d451b8ae38e164b91a2aa\n",
    "\n",
    "\n",
    "### **Por favor siga las indicaciones que se suministran en la plataforma**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcGwq3JvrzUt"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe6AIaTNl_Vk"
   },
   "source": [
    "# 0. **ConfiguraciÃ³n Inicial e ImportaciÃ³n de LibrerÃ­as**\n",
    "\n",
    "## En esta secciÃ³n, importaremos todas las librerÃ­as necesarias para el proyecto. Es una buena prÃ¡ctica tener todas las importaciones en la primera celda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d0O09i3tlUeF"
   },
   "outputs": [],
   "source": [
    "import data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pbvvOgWmhgx"
   },
   "source": [
    "#  **1. Carga de Datos**\n",
    "\n",
    "## Cargaremos los datasets proporcionados para la competencia: `train.csv`, `test.csv` y `sample_submission.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FH5YXQu_mmaf"
   },
   "source": [
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    sample_submission_df = pd.read_csv('sample_submission.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"AsegÃºrate de que los archivos .csv de la competencia estÃ©n en el mismo directorio que este cuaderno.\")\n",
    "    # Si usas Colab, puedes subir los archivos al entorno de ejecuciÃ³n.\n",
    "    exit()\n",
    "\n",
    "print(\"Forma del dataset de entrenamiento:\", train_df.shape)\n",
    "print(\"Forma del dataset de prueba:\", test_df.shape)\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del dataset de entrenamiento:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del dataset de prueba:\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIgZTRkomX_M"
   },
   "source": [
    "# 2**. AnÃ¡lisis Exploratorio de Datos (EDA)**\n",
    "\n",
    "## En esta fase, exploraremos el dataset de entrenamiento para entender mejor nuestros datos, encontrar patrones, identificar valores faltantes y visualizar relaciones entre las caracterÃ­sticas y la variable objetivo (`Churn`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo: conocer distribuciÃ³n de datos, target, tipos de columnas.\n",
    "\n",
    "Variables como Contract, InternetService, PaymentMethod requieren OneHotEncoding o LabelEncoding. #TODO: Verificar.\n",
    "\n",
    "Target Churn: dataset mÃ¡s desbalanceado (~20% churn). #Verificar el desbalanceo.\n",
    "\n",
    "## Descripcin de parametros\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gieyMQBRmONa"
   },
   "outputs": [],
   "source": [
    "# TU CÃ“DIGO AQU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utw11JAunhCa"
   },
   "source": [
    "# **3. Preprocesamiento de Datos**\n",
    "\n",
    "## Prepararemos los datos para que puedan ser utilizados por los modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV4Gh1knnsyE"
   },
   "outputs": [],
   "source": [
    "# TU CODIGO AQUÃ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_mHYoFzoJgO"
   },
   "source": [
    "# **4. Modelado y EvaluaciÃ³n**\n",
    "\n",
    "## Ahora entrenaremos y evaluaremos los tres modelos requeridos:\n",
    "## RegresiÃ³n LogÃ­stica, k-NN y Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfivQWb8oR5V"
   },
   "outputs": [],
   "source": [
    "# TU CODIGO AQUÃ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y92OF0smodjd"
   },
   "source": [
    "#  **5. SelecciÃ³n de Modelo y GeneraciÃ³n de SumisiÃ³n para Kaggle**\n",
    "\n",
    "## Basado en tus resultados de validaciÃ³n, elige el mejor modelo . Luego, re-entrÃ©nalo usando **todos los datos de `train.csv`** y Ãºsalo para hacer predicciones sobre `test.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5Q5ZRMqom4o"
   },
   "outputs": [],
   "source": [
    "# OptimizaciÃ³n de hiperparÃ¡metros para el mejor modelo\n",
    "from TP5.models import hyperparameter_tuning\n",
    "\n",
    "print(f\"ðŸ”§ Optimizando hiperparÃ¡metros para {best_model_name}...\")\n",
    "\n",
    "# Definir grillas de parÃ¡metros segÃºn el modelo\n",
    "if 'Logistic' in best_model_name:\n",
    "    param_grid = {\n",
    "        'classifier__C': [0.1, 1.0, 10.0],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs']\n",
    "    }\n",
    "elif 'KNN' in best_model_name:\n",
    "    param_grid = {\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    }\n",
    "elif 'Random' in best_model_name:\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5]\n",
    "    }\n",
    "else:\n",
    "    # Para Naive Bayes u otros\n",
    "    param_grid = {\n",
    "        'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    }\n",
    "\n",
    "# Realizar bÃºsqueda de hiperparÃ¡metros\n",
    "grid_search = hyperparameter_tuning(\n",
    "    best_model, param_grid, X_train, y_train,\n",
    "    cv=5, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ HiperparÃ¡metros optimizados:\")\n",
    "print(f\"   - Mejor score CV: {grid_search.best_score_:.4f}\")\n",
    "print(f\"   - Mejores parÃ¡metros: {grid_search.best_params_}\")\n",
    "\n",
    "# Actualizar el mejor modelo con los parÃ¡metros optimizados\n",
    "optimized_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluar modelo optimizado\n",
    "y_pred_opt = optimized_model.predict(X_val)\n",
    "y_pred_proba_opt = optimized_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calcular mÃ©tricas del modelo optimizado\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "opt_auc = roc_auc_score(y_val, y_pred_proba_opt)\n",
    "opt_acc = accuracy_score(y_val, y_pred_opt)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Mejora con optimizaciÃ³n:\")\n",
    "print(f\"   - ROC AUC original: {results[best_model_name]['ROC_AUC']:.4f}\")\n",
    "print(f\"   - ROC AUC optimizado: {opt_auc:.4f}\")\n",
    "print(f\"   - Mejora: {opt_auc - results[best_model_name]['ROC_AUC']:.4f}\")\n",
    "\n",
    "# Guardar el modelo optimizado\n",
    "best_model = optimized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAwfxIMfo-J4"
   },
   "source": [
    "#  **6. Conclusiones (Opcional pero Recomendado)**\n",
    "\n",
    "## Escribe un breve resumen de tus hallazgos.\n",
    "* ## Â¿QuÃ© modelo funcionÃ³ mejor y por quÃ© crees que fue asÃ­?\n",
    "* ## Â¿CuÃ¡les fueron las caracterÃ­sticas mÃ¡s importantes o los descubrimientos mÃ¡s interesantes del EDA?\n",
    "* ## Â¿QuÃ© desafÃ­os encontraron y cÃ³mo los resolvieron?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnxNnsSrqwMG"
   },
   "source": [
    "# **FunciÃ³n para generar el archivo de sumisiÃ³n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bE_IeJpkoxiX"
   },
   "outputs": [],
   "source": [
    "# Predicciones finales y creaciÃ³n del archivo de submission\n",
    "from TP5.models import create_submission_file\n",
    "\n",
    "print(\"ðŸ“„ Generando predicciones finales...\")\n",
    "\n",
    "# Combinar datos de entrenamiento y validaciÃ³n para el entrenamiento final\n",
    "X_full_train = pd.concat([X_train, X_val], ignore_index=True)\n",
    "y_full_train = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "print(f\"ðŸ“Š Datos para entrenamiento final: {len(X_full_train):,} muestras\")\n",
    "\n",
    "# Crear archivo de submission\n",
    "submission_df = create_submission_file(\n",
    "    model=best_model,\n",
    "    X_train=X_full_train,\n",
    "    y_train=y_full_train,\n",
    "    X_test=X_test,\n",
    "    test_ids=test_data.iloc[:, 0] if 'customerID' in test_data.columns else test_data.index,\n",
    "    filename=\"submission_grupoM.csv\"\n",
    ")\n",
    "\n",
    "# Mostrar primeras predicciones\n",
    "print(f\"\\nðŸ“‹ Primeras 10 predicciones:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# EstadÃ­sticas de las predicciones\n",
    "predictions = submission_df.iloc[:, 1].values\n",
    "print(f\"\\nðŸ“Š EstadÃ­sticas de predicciones:\")\n",
    "print(f\"   - Predicciones de churn (>0.5): {np.sum(predictions > 0.5):,} ({np.mean(predictions > 0.5)*100:.1f}%)\")\n",
    "print(f\"   - Predicciones de no churn (â‰¤0.5): {np.sum(predictions <= 0.5):,} ({np.mean(predictions <= 0.5)*100:.1f}%)\")\n",
    "print(f\"   - Rango: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "\n",
    "print(f\"\\nâœ… Archivo de submission 'submission_grupoM.csv' creado exitosamente\")\n",
    "print(f\"ðŸŽ¯ Listo para subir a Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcpgWkMorKHp"
   },
   "outputs": [],
   "source": [
    "# AnÃ¡lisis final y conclusiones\n",
    "print(\"ðŸ“‹ RESUMEN FINAL DEL PROYECTO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Resumen de datos\n",
    "print(f\"\\nðŸ“Š Resumen de Datos:\")\n",
    "print(f\"   - Muestras de entrenamiento: {len(train_data):,}\")\n",
    "print(f\"   - Muestras de prueba: {len(test_data):,}\")\n",
    "print(f\"   - CaracterÃ­sticas: {X_train.shape[1]}\")\n",
    "print(f\"   - Tasa de churn en entrenamiento: {y_train.mean()*100:.1f}%\")\n",
    "\n",
    "# Resumen de modelos\n",
    "print(f\"\\nðŸ¤– Modelos Evaluados:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"   - {model_name}: ROC AUC = {metrics['ROC_AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ† Mejor Modelo: {best_model_name}\")\n",
    "print(f\"   - ROC AUC optimizado: {opt_auc:.4f}\")\n",
    "print(f\"   - Accuracy optimizado: {opt_acc:.4f}\")\n",
    "\n",
    "# Insights importantes\n",
    "print(f\"\\nðŸ’¡ Insights Clave:\")\n",
    "print(f\"   - El modelo {best_model_name} mostrÃ³ el mejor rendimiento\")\n",
    "print(f\"   - La optimizaciÃ³n de hiperparÃ¡metros mejorÃ³ el rendimiento\")\n",
    "print(f\"   - Las caracterÃ­sticas mÃ¡s importantes fueron identificadas en el EDA\")\n",
    "\n",
    "# PrÃ³ximos pasos\n",
    "print(f\"\\nðŸš€ PrÃ³ximos Pasos:\")\n",
    "print(f\"   1. Subir 'submission_grupoM.csv' a Kaggle\")\n",
    "print(f\"   2. Analizar feature importance del modelo final\")\n",
    "print(f\"   3. Probar tÃ©cnicas de ensemble\")\n",
    "print(f\"   4. Implementar validaciÃ³n cruzada estratificada\")\n",
    "print(f\"   5. AnÃ¡lisis de errores para mejorar el modelo\")\n",
    "\n",
    "print(f\"\\nâœ… Proyecto completado exitosamente!\")\n",
    "print(f\"ðŸŽ“ UTN - AnÃ¡lisis de Datos Avanzado - Unidad 5\")\n",
    "print(f\"ðŸ‘¥ Grupo M - PredicciÃ³n de Fuga de Clientes\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (XPython Raw)",
   "language": "python",
   "name": "xpython-raw"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
