{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Image in a markdown cell](https://cursos.utnba.centrodeelearning.com/pluginfile.php/1/theme_space/customlogo/1738330016/Logo%20UTN%20Horizontal.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "3NGbiFnclWCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diplomado de Ciencia de Datos y Análisis Avanzado**\n",
        "# **Unidad 5: Modelado Predictivo I**: Regresión y Clasificación"
      ],
      "metadata": {
        "id": "QuprUYNItamA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Fwq174zItdhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Proyecto de Competencia Kaggle: Predicción de Abandono de Clientes**\n",
        "\n",
        "## **Curso:** Diplomado en Ciencia de Datos\n",
        "\n",
        "# **Nombres de los Miembros del Equipo:**\n",
        "### *   [Nombre Completo del Miembro 1]\n",
        "### *   [Nombre Completo del Miembro 2]\n",
        "### *   [Nombre Completo del Miembro 3]\n",
        "\n",
        "# **Objetivo:**\n",
        "## El objetivo de este proyecto es construir y evaluar varios modelos de clasificación para predecir si un cliente de una compañía de telecomunicaciones abandonará o no el servicio (churn). El rendimiento final del mejor modelo se medirá en la competencia de Kaggle a través de la **métrica ROC AUC**.\n"
      ],
      "metadata": {
        "id": "5hA-KQxHlV2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fqk8OzCZrz9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enlace para unirse a la competencia**\n",
        "### **USE EL ENLACE PARA UNIRSE POR EQUIPO, NO DE MANERA INDIVIDUAL**\n",
        "\n",
        "https://www.kaggle.com/t/57b70c381e4d451b8ae38e164b91a2aa\n",
        "\n",
        "\n",
        "### **Por favor siga las indicaciones que se suministran en la plataforma**\n"
      ],
      "metadata": {
        "id": "C4oEVvfDr2BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FcGwq3JvrzUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. **Configuración Inicial e Importación de Librerías**\n",
        "\n",
        "## En esta sección, importaremos todas las librerías necesarias para el proyecto. Es una buena práctica tener todas las importaciones en la primera celda.\n"
      ],
      "metadata": {
        "id": "pe6AIaTNl_Vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0O09i3tlUeF"
      },
      "outputs": [],
      "source": [
        "# Para manipulación de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Para visualización de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Para preprocesamiento\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Para modelado\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Para evaluación\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, f1_score\n",
        "\n",
        "# Configuraciones adicionales para una mejor visualización\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "# Ignorar warnings para una salida más limpia (opcional)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **1. Carga de Datos**\n",
        "\n",
        "## Cargaremos los datasets proporcionados para la competencia: `train.csv`, `test.csv` y `sample_submission.csv`.\n"
      ],
      "metadata": {
        "id": "0pbvvOgWmhgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    sample_submission_df = pd.read_csv('sample_submission.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Asegúrate de que los archivos .csv de la competencia estén en el mismo directorio que este cuaderno.\")\n",
        "    # Si usas Colab, puedes subir los archivos al entorno de ejecución.\n",
        "    exit()\n",
        "\n",
        "print(\"Forma del dataset de entrenamiento:\", train_df.shape)\n",
        "print(\"Forma del dataset de prueba:\", test_df.shape)\n",
        "\n",
        "print(\"\\nPrimeras 5 filas del dataset de entrenamiento:\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(\"\\nPrimeras 5 filas del dataset de prueba:\")\n",
        "display(test_df.head())"
      ],
      "metadata": {
        "id": "FH5YXQu_mmaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2**. Análisis Exploratorio de Datos (EDA)**\n",
        "\n",
        "## En esta fase, exploraremos el dataset de entrenamiento para entender mejor nuestros datos, encontrar patrones, identificar valores faltantes y visualizar relaciones entre las características y la variable objetivo (`Churn`).\n"
      ],
      "metadata": {
        "id": "bIgZTRkomX_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TU CÓDIGO AQUÍ\n"
      ],
      "metadata": {
        "id": "gieyMQBRmONa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Preprocesamiento de Datos**\n",
        "\n",
        "## Prepararemos los datos para que puedan ser utilizados por los modelos de Machine Learning."
      ],
      "metadata": {
        "id": "utw11JAunhCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TU CODIGO AQUÍ\n"
      ],
      "metadata": {
        "id": "hV4Gh1knnsyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Modelado y Evaluación**\n",
        "\n",
        "## Ahora entrenaremos y evaluaremos los tres modelos requeridos:\n",
        "## Regresión Logística, k-NN y Naive Bayes.\n"
      ],
      "metadata": {
        "id": "S_mHYoFzoJgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TU CODIGO AQUÍ\n"
      ],
      "metadata": {
        "id": "QfivQWb8oR5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **5. Selección de Modelo y Generación de Sumisión para Kaggle**\n",
        "\n",
        "## Basado en tus resultados de validación, elige el mejor modelo . Luego, re-entrénalo usando **todos los datos de `train.csv`** y úsalo para hacer predicciones sobre `test.csv`.\n"
      ],
      "metadata": {
        "id": "y92OF0smodjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TU CÓDIGO AQUÍ\n"
      ],
      "metadata": {
        "id": "q5Q5ZRMqom4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **6. Conclusiones (Opcional pero Recomendado)**\n",
        "\n",
        "## Escribe un breve resumen de tus hallazgos.\n",
        "* ## ¿Qué modelo funcionó mejor y por qué crees que fue así?\n",
        "* ## ¿Cuáles fueron las características más importantes o los descubrimientos más interesantes del EDA?\n",
        "* ## ¿Qué desafíos encontraron y cómo los resolvieron?\n"
      ],
      "metadata": {
        "id": "uAwfxIMfo-J4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Función para generar el archivo de sumisión**"
      ],
      "metadata": {
        "id": "EnxNnsSrqwMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_submission_file(final_model, X_train_full, y_train_full, X_test_full, customer_ids, filename=\"submission.csv\"):\n",
        "    \"\"\"\n",
        "    Entrena el modelo final con todos los datos de entrenamiento, genera predicciones\n",
        "    de probabilidad en el conjunto de prueba y guarda el archivo de sumisión.\n",
        "\n",
        "    Args:\n",
        "        final_model: El modelo y preprocesamiento elegido.\n",
        "        X_train_full (DataFrame): El DataFrame completo de características de entrenamiento.\n",
        "        y_train_full (Series): La Serie completa del objetivo de entrenamiento.\n",
        "        X_test_full (DataFrame): El DataFrame de características de prueba.\n",
        "        customer_ids (Series): La Serie de customerID para el archivo de sumisión.\n",
        "        filename (str): El nombre del archivo CSV de salida.\n",
        "    \"\"\"\n",
        "    print(\"Entrenando el modelo final con todos los datos de entrenamiento...\")\n",
        "    final_model.fit(X_train_full, y_train_full)\n",
        "    print(\"Modelo final entrenado.\")\n",
        "\n",
        "    print(\"Generando predicciones de probabilidad sobre el conjunto de prueba...\")\n",
        "    test_probabilities = final_model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "    print(f\"Creando el archivo de sumisión '{filename}'...\")\n",
        "    submission_df = pd.DataFrame({\n",
        "        'customerID': customer_ids,\n",
        "        'Churn': test_probabilities\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Archivo '{filename}' generado exitosamente.\")\n",
        "    print(\"Primeras 5 filas del archivo de sumisión:\")\n",
        "    display(submission_df.head())\n",
        "    return submission_df"
      ],
      "metadata": {
        "id": "bE_IeJpkoxiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_final = generar_submission_file(\n",
        "    final_model=mejor_modelo,\n",
        "    X_train_full=X,\n",
        "    y_train_full=y,\n",
        "    X_test_full=X_test_final,\n",
        "    customer_ids=test_customer_ids,\n",
        "    filename=\"mi_submission_final.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "AcpgWkMorKHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}