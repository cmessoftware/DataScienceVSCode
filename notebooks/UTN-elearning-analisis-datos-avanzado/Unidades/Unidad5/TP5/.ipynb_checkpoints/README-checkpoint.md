# Data Science VSCode - Entorno Docker

Este proyecto proporciona un entorno completo de Data Science utilizando Docker y Jupyter Lab, optimizado para el anÃ¡lisis de datos avanzado.

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- Docker Desktop instalado
- **PowerShell (Windows) - Recomendado** para usar los scripts automÃ¡ticos
- **Alternativas sin PowerShell**: CMD, Git Bash, o comandos Docker directos (ver secciÃ³n [Usuarios de Windows sin PowerShell](#ğŸ–¥ï¸-usuarios-de-windows-sin-powershell))

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

#### Uso bÃ¡sico:
```powershell
.\quick-start.ps1
```

#### Opciones avanzadas:
```powershell
.\quick-start.ps1 -Help                    # Ver ayuda
.\quick-start.ps1 -SkipBuild              # Solo iniciar (imagen ya existe)
.\quick-start.ps1 -ShowLogs               # Mostrar logs al final
.\quick-start.ps1 -OpenBrowser:$false     # No abrir navegador automÃ¡ticamente
```

#### Detener servicios:
```powershell
.\quick-stop.ps1
```

### OpciÃ³n 2: ConfiguraciÃ³n Manual

1. **Construir la imagen Docker:**
   ```powershell
   .\docker-helper.ps1 build
   ```

2. **Iniciar Jupyter Lab:**
   ```powershell
   .\docker-helper.ps1 start
   ```

3. **Acceder a Jupyter Lab:**
   - URL: http://localhost:8888
   - Token: `datascience2024`

## ğŸ“‹ Comandos Disponibles

### GestiÃ³n de Servicios
```powershell
.\docker-helper.ps1 build     # Construir imagen
.\docker-helper.ps1 start     # Iniciar servicios
.\docker-helper.ps1 stop      # Detener servicios
.\docker-helper.ps1 restart   # Reiniciar servicios
.\docker-helper.ps1 status    # Ver estado
```

### Desarrollo y Debugging
```powershell
.\docker-helper.ps1 shell     # Abrir shell en contenedor
.\docker-helper.ps1 python    # Consola Python interactiva
.\docker-helper.ps1 logs      # Ver logs
```

### GestiÃ³n de Paquetes
```powershell
.\docker-helper.ps1 install pandas    # Instalar paquete
.\docker-helper.ps1 install numpy     # Instalar otro paquete
```

### Utilidades
```powershell
.\docker-helper.ps1 backup    # Backup de notebooks
.\docker-helper.ps1 info      # InformaciÃ³n de Jupyter
.\docker-helper.ps1 clean     # Limpiar Docker
.\docker-helper.ps1 help      # Mostrar ayuda
```

## ğŸ“ Estructura del Proyecto

```
DataScienceVSCode/
â”œâ”€â”€ UTN-elearning-analisis-datos-avanzado/  # Notebooks principales
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ clases/
â”‚   â”‚   â”‚   â”œâ”€â”€ ch1/ - ch4/                 # CapÃ­tulos del curso
â”‚   â”‚   â”‚   â””â”€â”€ tbc/                        # AnÃ¡lisis TBC
â”‚   â”‚   â””â”€â”€ custom_tools/
â”œâ”€â”€ docker-helper.ps1                       # Script de gestiÃ³n
â”œâ”€â”€ docker-compose.yml                      # ConfiguraciÃ³n Docker
â”œâ”€â”€ Dockerfile                              # Imagen personalizada
â””â”€â”€ requirements.txt                        # Dependencias Python
```

## ğŸ› ï¸ Paquetes Incluidos

### Core Data Science
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - ComputaciÃ³n numÃ©rica
- **matplotlib** - VisualizaciÃ³n bÃ¡sica
- **seaborn** - VisualizaciÃ³n estadÃ­stica
- **plotly** - VisualizaciÃ³n interactiva

### Machine Learning
- **scikit-learn** - Algoritmos ML
- **statsmodels** - Modelos estadÃ­sticos
- **scipy** - ComputaciÃ³n cientÃ­fica

### Jupyter Ecosystem
- **jupyterlab** - Interfaz principal
- **ipywidgets** - Widgets interactivos
- **jupyter-contrib-nbextensions** - Extensiones

### Utilidades
- **tqdm** - Barras de progreso
- **pyarrow** - Formato de datos eficiente
- **openpyxl** - Lectura/escritura Excel

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Puertos
- **8888**: Jupyter Lab (principal)
- **8889**: Puerto alternativo (disponible)

### VolÃºmenes
- **CÃ³digo fuente**: `/workspace` (todo el proyecto)
- **Notebooks**: `/workspace/notebooks` (UTN notebooks)
- **Labs**: `/workspace/ISLP_labs` (ISLP exercises)

### Variables de Entorno
- `JUPYTER_TOKEN=datascience2024`
- `JUPYTER_ROOT_DIR=/workspace`

## ğŸš¨ SoluciÃ³n de Problemas

### Error de permisos
```powershell
# En PowerShell como administrador
Set-ExecutionPolicy RemoteSigned
```

### Error de permisos con scripts
```powershell
# Ejecutar solo para la sesiÃ³n actual
Set-ExecutionPolicy Bypass -Scope Process -Force
.\quick-start.ps1
```

### PowerShell no reconoce el script
```powershell
# Usar ruta completa
PowerShell.exe -ExecutionPolicy Bypass -File ".\quick-start.ps1"
```

### Puerto ocupado
```powershell
# Cambiar puerto en docker-compose.yml
ports:
  - "8801:8802"  # Usar puerto alternativo
```

### Memoria insuficiente
```powershell
# Aumentar memoria en Docker Desktop
# Settings > Resources > Memory > 4GB+
```

### ğŸ–¥ï¸ Usuarios de Windows sin PowerShell

Si tu sistema Windows no tiene PowerShell disponible o prefieres usar CMD/SÃ­mbolo del sistema, puedes usar estos comandos alternativos:

#### OpciÃ³n 1: Usando CMD (SÃ­mbolo del sistema)

1. **Construir la imagen Docker:**
   ```cmd
   docker-compose build
   ```

2. **Iniciar Jupyter Lab:**
   ```cmd
   docker-compose up -d
   ```

3. **Ver estado de los contenedores:**
   ```cmd
   docker ps
   ```

4. **Detener servicios:**
   ```cmd
   docker-compose down
   ```

5. **Ver logs:**
   ```cmd
   docker-compose logs
   ```

#### OpciÃ³n 2: Comandos Docker directos

1. **Construir imagen:**
   ```cmd
   docker build -t datascience-vscode .
   ```

2. **Ejecutar contenedor:**
   ```cmd
   docker run -d -p 8888:8888 -v "%cd%":/workspace --name jupyter-lab datascience-vscode
   ```

3. **Detener contenedor:**
   ```cmd
   docker stop jupyter-lab
   docker rm jupyter-lab
   ```

#### OpciÃ³n 3: Usar Git Bash (si tienes Git instalado)

Git Bash incluye un shell similar a Linux que puede ejecutar scripts bÃ¡sicos:

```bash
# Navegar al directorio del proyecto
cd /c/ruta/a/tu/proyecto

# Usar docker-compose
docker-compose up -d
docker-compose down
```

#### Acceder a Jupyter Lab sin scripts
Independientemente del mÃ©todo usado:
- **URL**: http://localhost:8888
- **Token**: `datascience2024`
- Si el puerto 8888 estÃ¡ ocupado, cambia el puerto en `docker-compose.yml`

### Ejercicios por CapÃ­tulo
- **Unidad1**: AnÃ¡lisis de familias
- **Unidad2**: Distribuciones de probabilidad
- **Unidad3**: Modelos binomiales e hipergeomÃ©tricos
- **Unidad4**: Actividades prÃ¡cticas con MPG dataset
- **Unidad5**: Predicciones y clasificaciones, introducciÃ³n ML.

---

## ğŸ“’ Tutorial: Notebook de PredicciÃ³n de Fuga de Clientes (Churn)

Este proyecto incluye un notebook completo para el problema de predicciÃ³n de abandono de clientes (churn), ideal para competencias de Kaggle y prÃ¡cticas de Machine Learning.

### ğŸ“ UbicaciÃ³n del notebook

```
notebooks/
â””â”€â”€ UTN-elearning-analisis-datos-avanzado/
    â””â”€â”€ Unidades/
        â””â”€â”€ Unidad5/
            â””â”€â”€ TP5/
                â””â”€â”€ tp5_grupoM.ipynbP
                â””â”€â”€ tp5_grupoM_backup.ipynb
```

## ğŸ“– Diccionario de datos â€” Telco Customer Churn

DescripciÃ³n de cada campo en el dataset, en lenguaje de negocio:

| Campo | DescripciÃ³n |
| ----- | ----------- |
| **customerID** | Identificador Ãºnico del cliente. Solo referencia; no es Ãºtil como predictor. |
| **gender** | GÃ©nero del cliente (`Male` / `Female`). |
| **SeniorCitizen** | Si el cliente es adulto mayor (`1` = sÃ­; `0` = no). |
| **Partner** | Si el cliente tiene pareja (`Yes` / `No`). |
| **Dependents** | Si tiene dependientes (hijos, familiares a cargo) (`Yes` / `No`). |
| **tenure** | AntigÃ¼edad: cantidad de meses como cliente. Predictor clave: churn tiende a ser mayor en clientes nuevos. |
| **PhoneService** | Si tiene lÃ­nea telefÃ³nica (`Yes` / `No`). |
| **MultipleLines** | Si tiene mÃ¡s de una lÃ­nea (`Yes` / `No` / `No phone service`). |
| **InternetService** | Tipo de conexiÃ³n a internet (`DSL` / `Fiber optic` / `No`). |
| **OnlineSecurity** | Si tiene servicio de seguridad online contratado (`Yes` / `No` / `No internet service`). |
| **OnlineBackup** | Si tiene servicio de backup online contratado (`Yes` / `No` / `No internet service`). |
| **DeviceProtection** | Si tiene protecciÃ³n de dispositivos (`Yes` / `No` / `No internet service`). |
| **TechSupport** | Si tiene soporte tÃ©cnico contratado (`Yes` / `No` / `No internet service`). |
| **StreamingTV** | Si tiene servicio de streaming TV contratado (`Yes` / `No` / `No internet service`). |
| **StreamingMovies** | Si tiene servicio de streaming de pelÃ­culas (`Yes` / `No` / `No internet service`). |
| **Contract** | Tipo de contrato (`Month-to-month` / `One year` / `Two year`). Alta relevancia: contratos mÃ¡s largos tienden a tener menor churn. |
| **PaperlessBilling** | Si usa facturaciÃ³n electrÃ³nica (`Yes` / `No`). |
| **PaymentMethod** | MÃ©todo de pago (`Electronic check` / `Mailed check` / `Bank transfer (automatic)` / `Credit card (automatic)`). |
| **MonthlyCharges** | Importe mensual facturado al cliente (en USD). |
| **TotalCharges** | Total acumulado facturado durante toda la relaciÃ³n comercial. |
| **Churn** | ğŸ¯ **Variable objetivo:** indica si el cliente abandonÃ³ (`Yes`) o sigue (`No`). |

---

âœ… **Notas importantes:**
- Muchos campos son categÃ³ricos y requieren encoding adecuado.
- `TotalCharges` contiene algunos valores no numÃ©ricos (" ") que deben limpiarse antes de usar.
- `Churn` estÃ¡ desbalanceado (~20% Yes), por lo que deben usarse mÃ©tricas y tÃ©cnicas adecuadas.

---

Este diccionario sirve como referencia de negocio para comprender la estructura de datos y facilitar el anÃ¡lisis exploratorio (EDA) y modelado predictivo.


### ğŸ“ Â¿QuÃ© contiene el notebook?
- **IntroducciÃ³n y contexto del problema**
- **ImportaciÃ³n de librerÃ­as y mÃ³dulos**
- **Carga y exploraciÃ³n de datos**
- **EDA (AnÃ¡lisis exploratorio de datos)**
- **Preprocesamiento y limpieza**
- **Entrenamiento de modelos (Logistic Regression, k-NN, Naive Bayes, etc.)**
- **EvaluaciÃ³n y selecciÃ³n del mejor modelo**
- **GeneraciÃ³n de archivo de submission para Kaggle**
- **Conclusiones y recomendaciones**

### ğŸš¦ Â¿CÃ³mo usar el notebook?

1. **Accede a Jupyter Lab**
   - URL: http://localhost:8888
   - Token: `datascience2024`

2. **Navega a la carpeta  `notebooks/UTN-elearning-analisis-datos-avanzado/Unidades/Unidad5/TP5/`**

3. **Abre el notebook `tp5_grupoM_backup.ipynb`**
   - Si el archivo principal da error, usa el backup.
   - Puedes renombrar el backup si lo deseas.

4. **Ejecuta las celdas paso a paso**
   - Sigue las instrucciones y comentarios en cada celda.
   - Modifica los parÃ¡metros y cÃ³digo segÃºn tu equipo y datos.

5. **Carga tus datasets**
   - Coloca los archivos `train.csv`, `test.csv` y `sample_submission.csv` en la misma carpeta que el notebook.
   - Si no tienes los datos, el notebook genera datos de ejemplo para pruebas.

6. **Entrena y evalÃºa modelos**
   - El notebook incluye cÃ³digo para entrenar varios modelos y comparar resultados.
   - Puedes agregar nuevos modelos o modificar los existentes.

7. **Genera el archivo de submission para Kaggle**
   - Sigue las instrucciones en la Ãºltima secciÃ³n para crear el archivo `.csv` listo para subir a la competencia.
  


## ğŸ”§ Conceptos Clave de Machine Learning

### ğŸ“Š PreparaciÃ³n de Datos (Feature Engineering)

#### **Â¿Por quÃ© remover `Churn` y `customerID` al crear caracterÃ­sticas?**

En el notebook, verÃ¡s esta lÃ­nea de cÃ³digo:
```python
# Extraer caracterÃ­sticas (X_features) - remover Churn y customerID
columns_to_drop = ['Churn']
if 'customerID' in X_train.columns:
    columns_to_drop.append('customerID')

X_features = X_train.drop(columns_to_drop, axis=1)
```

**ExplicaciÃ³n:**

1. **Remover `Churn` (Variable Objetivo)**
   - **`Churn`** es la **variable que queremos predecir** (target/objetivo)
   - En machine learning, **NO puedes usar la variable objetivo como caracterÃ­stica** para entrenar el modelo
   - SerÃ­a como hacer trampa: "predice si el cliente se va, usando como dato si el cliente se va"
   - **SeparaciÃ³n obligatoria**:
     - `y = X_train['Churn']` â†’ Lo que queremos predecir
     - `X_features` â†’ Las caracterÃ­sticas que usamos para hacer la predicciÃ³n

2. **Remover `customerID` (Identificador)**
   - **`customerID`** es solo un **identificador Ãºnico** (como "CUST001", "CUST002")
   - **No aporta informaciÃ³n predictiva** sobre si un cliente se irÃ¡ o no
   - Los modelos podrÃ­an memorizar estos IDs y crear **overfitting**
   - Es informaciÃ³n administrativa, no predictiva

#### **AnalogÃ­a prÃ¡ctica:**
Imagina que quieres predecir si va a llover:

```python
# âŒ INCORRECTO
X_features = ['temperatura', 'humedad', 'presiÃ³n', 'va_a_llover', 'id_medicion']
y = 'va_a_llover'  # Â¡Usas lo mismo que quieres predecir!

# âœ… CORRECTO  
X_features = ['temperatura', 'humedad', 'presiÃ³n']  # Solo caracterÃ­sticas Ãºtiles
y = 'va_a_llover'  # Lo que quieres predecir
```

#### **Flujo correcto en el proyecto:**
```python
# 1. Extraer variable objetivo
y = X_train['Churn']  # Target: 0 (no churn) o 1 (churn)

# 2. Extraer caracterÃ­sticas (sin Churn y customerID)  
X_features = X_train.drop(['Churn', 'customerID'], axis=1)

# 3. Dividir en train/validation
X_train_split, X_val, y_train_split, y_val = train_test_split(
    X_features, y, test_size=0.2, random_state=42, stratify=y
)
```


### ğŸ’¡ Consejos Ãºtiles
- Si el notebook original no abre, usa el backup (`_backup.ipynb`).
- Puedes duplicar el notebook para hacer pruebas sin perder el original.
- Si tienes errores de importaciÃ³n, revisa que los mÃ³dulos `.py` estÃ©n en la misma carpeta.
- Usa las celdas de markdown para documentar tu trabajo y conclusiones.

### ğŸ† Â¿QuÃ© aprenderÃ¡s?
- PrÃ¡ctica completa de un workflow de Machine Learning real.
- CÃ³mo preparar datos, entrenar y evaluar modelos.
- CÃ³mo participar en competencias de Kaggle.
- CÃ³mo documentar y presentar resultados en notebooks.

---

## ğŸ¯ Â¡MLflow Implementado Exitosamente!

He integrado **MLflow** completo en tu proyecto para gestionar los diferentes experimentos de ML. AquÃ­ estÃ¡ lo que se implementÃ³:

### âœ… **Funcionalidades Implementadas:**

#### 1. **ğŸ”§ ConfiguraciÃ³n AutomÃ¡tica**
- MLflow configurado en el notebook con tracking local
- Experimento `Churn_Prediction_TP5` creado automÃ¡ticamente
- FunciÃ³n helper `log_model_metrics()` para registro consistente

#### 2. **ğŸ“Š Tracking de Modelos Base**
- Todos los modelos (Logistic Regression, KNN, Naive Bayes, Random Forest) se registran automÃ¡ticamente
- MÃ©tricas: ROC AUC, Accuracy, Precision, Recall, F1-Score
- HiperparÃ¡metros y configuraciones guardadas

#### 3. **ğŸ¯ Tracking de OptimizaciÃ³n**
- Modelos optimizados con tag `_OPTIMIZED`
- ComparaciÃ³n automÃ¡tica original vs optimizado
- Registro de mejoras/deterioros en mÃ©tricas

#### 4. **ğŸ“ˆ Dashboard Interactivo**
- Servidor MLflow UI iniciado en `http://localhost:5000`
- ComparaciÃ³n visual de todos los modelos
- GrÃ¡ficos automÃ¡ticos de mÃ©tricas principales

#### 5. **ğŸ› ï¸ Herramientas Adicionales**
- `mlflow_analysis.py`: Script para anÃ¡lisis avanzado
- `start_mlflow.bat`: Launcher rÃ¡pido del servidor
- `MLflow_README.md`: GuÃ­a completa de uso

### ğŸš€ **Para Usar MLflow Ahora:**

#### **OpciÃ³n 1: Dashboard Web (Recomendado)**
1. Ejecuta `start_mlflow.bat` o navega a `http://localhost:5000`
2. Busca el experimento "Churn_Prediction_TP5"
3. Compara todos tus modelos visualmente

#### **OpciÃ³n 2: Ejecutar Notebook**
- Las celdas modificadas automÃ¡ticamente registrarÃ¡n todos los experimentos
- Cada modelo se guarda con sus mÃ©tricas y parÃ¡metros

#### **OpciÃ³n 3: AnÃ¡lisis Personalizado**
```bash
cd notebooks\UTN-elearning-analisis-datos-avanzado\Unidades\Unidad5\TP5
python mlflow_analysis.py
```

### ğŸ” **Â¿Por quÃ© la VersiÃ³n Optimizada Obtuvo Menor Score?**

Esto es comÃºn en ML y puede deberse a:

1. **Overfitting**: Los hiperparÃ¡metros optimizados se ajustaron demasiado a los datos de validaciÃ³n
2. **ConfiguraciÃ³n de Grid Search**: La grilla de parÃ¡metros podrÃ­a no ser la Ã³ptima
3. **Datos de ValidaciÃ³n**: El conjunto de validaciÃ³n pequeÃ±o puede no ser representativo
4. **Randomness**: Diferentes semillas aleatorias pueden afectar los resultados

### ğŸ“Š **Con MLflow Puedes:**
- **Comparar objetivamente** todos los modelos y sus variantes
- **Identificar quÃ© hiperparÃ¡metros** funcionan mejor
- **Reproducir exactamente** cualquier experimento
- **Visualizar trends** y patrones en tus optimizaciones

### ğŸ’¡ **PrÃ³ximos Pasos Recomendados:**
1. **Ejecuta el notebook** para que se registren todos los experimentos
2. **Explora el dashboard** en `http://localhost:5000`
3. **Analiza quÃ© modelos** realmente funcionan mejor
4. **Ajusta la estrategia de optimizaciÃ³n** basado en los datos del dashboard

Â¡Ahora tienes un sistema profesional de gestiÃ³n de experimentos ML que te permitirÃ¡ tomar decisiones informadas sobre quÃ© modelos usar para la competencia de Kaggle! ğŸ†

---

## ğŸ—‚ï¸ NavegaciÃ³n RÃ¡pida

### Para Usuarios de PowerShell
- [Inicio RÃ¡pido con Scripts](#ğŸš€-inicio-rÃ¡pido) - MÃ©todo recomendado
- [Comandos PowerShell Disponibles](#ğŸ“‹-comandos-disponibles)
- [SoluciÃ³n de Problemas PowerShell](#ğŸš¨-soluciÃ³n-de-problemas)

### Para Usuarios sin PowerShell
- [ğŸ–¥ï¸ Usuarios de Windows sin PowerShell](#ğŸ–¥ï¸-usuarios-de-windows-sin-powershell)
  - [Comandos CMD](#opciÃ³n-1-usando-cmd-sÃ­mbolo-del-sistema)
  - [Docker Directo](#opciÃ³n-2-comandos-docker-directos)
  - [Git Bash](#opciÃ³n-3-usar-git-bash-si-tienes-git-instalado)

### Recursos de Aprendizaje
- [Tutorial Completo de Churn Prediction](#ğŸ“’-tutorial-notebook-de-predicciÃ³n-de-fuga-de-clientes-churn)
- [Diccionario de Datos](#ğŸ“–-diccionario-de-datos--telco-customer-churn)
- [Conceptos Clave de ML](#ğŸ”§-conceptos-clave-de-machine-learning)

### ğŸ¯ MLflow - GestiÃ³n de Experimentos
- [ImplementaciÃ³n Completa de MLflow](#ğŸ¯-mlflow-implementado-exitosamente) - Sistema de tracking de experimentos
- [GuÃ­a Detallada de MLflow](MLflow_README.md) - DocumentaciÃ³n tÃ©cnica completa
- Dashboard Web: `http://localhost:5000` (despuÃ©s de ejecutar `start_mlflow.bat`)

---

