{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Outline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Topics\n",
      "\n",
      "* Nonparametric regression.\n",
      "* Bootstrap.\n",
      "* Time series."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Nonparametric regression\n",
      "\n",
      "* We\u2019ve focused on linear regression: ${\\mathop{\\mathrm{minimize}}}_{\\beta} \\frac{1}{2} \\|Y-X\\beta^2\\|^2_2.$\n",
      "* Equivalent to ${\\mathop{\\mathrm{minimize}}}_{f_j} \\frac{1}{2} \\|Y-\\sum_{j=1}^p f_j(X)\\|^2_2.$ where $f_j \\in \\left\\{(x^Te_j) \\cdot \\beta_j: \\beta_j \\in {\\mathbb{R}}\\right\\} = {\\cal F}_j$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Nonparametric regression\n",
      "\n",
      "* The class ${\\cal F}_j$ can be changed.\n",
      "* For instance, we might take ${\\cal F}_j = \\left\\{f = g_j(x_j) \\right\\}$ so our problem is ${\\mathop{\\mathrm{minimize}}}_{\\beta} \\frac{1}{2} \\|Y-\\sum_{j=1}^p f_j(X_j)\\|^2_2.$\n",
      "* This called an *additive*\n",
      "   model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Nonparametric regression\n",
      "\n",
      "* The class ${\\cal F}_j$ is too big \u2013 we need to penalize it.\n",
      "* Ideally, penalty should make it smoother.\n",
      "* One example. ${\\cal P}(f) = \\int_{-\\infty}^{\\infty} (f''(x))^2 \\; dx$\n",
      "* This leads to ${\\mathop{\\mathrm{minimize}}}_{f_1, \\dots, f_p} \\frac{1}{2} \\|Y-\\sum_{j=1}^p f_j(X_j)\\|^2_2 +\n",
      "         \\lambda \\sum_{j=1}^p \\int_{-\\infty}^{\\infty} (f_j''(x))^2 \\; dx.$\n",
      "* This called an *additive*\n",
      "   model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Generalized additive model\n",
      "\n",
      "* The squared error part can be replaced by logistic or Poisson deviance.\n",
      "* Leads to a Generalized Additive Model (GAM) ${\\mathop{\\mathrm{minimize}}}_{f_1, \\dots, f_p} DEV(Y;\\sum_{j=1}^p f_j(X_j)) +\n",
      "         \\lambda \\sum_{j=1}^p \\int_{-\\infty}^{\\infty} (f_j''(x))^2 \\; dx.$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Kernel trick\n",
      "\n",
      "* The quadratic penalty on the derivative can be replaced by what is known as a kernel penalty\n",
      "* Leads to a Generalized Additive Model (GAM) ${\\mathop{\\mathrm{minimize}}}_{f_1, \\dots, f_p} DEV(Y;\\sum_{j=1}^p f_j(X_j)) +\n",
      "         \\lambda \\sum_{j=1}^p \\|f_j\\|^2_{{\\cal H}_j}.$\n",
      "* Known as *kernelizing*\n",
      "   or using the *kernel trick*\n",
      "  .\n",
      "* STATS315A would be a good course to see more of this."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Nonparametric Inference\n",
      "\n",
      "1. Much of the distributions we\u2019ve been using all quarter rely heavily on a Gaussian assumption.\n",
      "1. Of course, this may not be true in practice.\n",
      "1. If we\u2019re willing to assume independence of the pairs $(X_i,Y_i)$ then there are some non-parametric ways to perform inference."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Bootstrap\n",
      "\n",
      "1. Suppose we want to find a confidence interval for $\\beta_j$.\n",
      "1. Do the following:\n",
      "1.     1. For $1 \\leq b \\leq B$: sample $n$ pairs $(X_i,Y_i)$ with replacement from the original sample. Call this bootstrap sample $X^b, Y^b$\n",
      "       1. Form $\\hat{\\beta}^b = ((X^b)^TX^b)^{-1} (X^b)^TY^b$ and store $\\hat{\\beta}^b_j$.\n",
      "       1. Take the empirical 2.5% and 97.5% empirical quantiles of $\\left\\{\\hat{\\beta}^b_j: 1 \\leq b \\leq B\\right\\}.$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Tests of correlation\n",
      "\n",
      "* Suppose $p=1$ and we just want to know if $X$ and $Y$ are correlated but we don\u2019t believe the Gaussian assumption.\n",
      "* Then, Spearman\u2019s correlation coefficient converts each $X$ and $Y$ to ranks $R_X, R_Y$.\n",
      "* Test statistic is the $\\sqrt{R^2}$ from regressing $R_Y$ onto $R_X$.\n",
      "* Its null distribution does not depend heavily on the marginal distributions of $X$ and $Y$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Two sample tests\n",
      "\n",
      "* Suppose we are looking at the two group problem and want to test whether there is a difference in means between the two groups.\n",
      "* Do the following:\n",
      "*     1. Compute the usual $T$ statistic to test the difference between the two.\n",
      "      1. For $1 \\leq b \\leq B$: randomize the assignment of the $Y_i$\u2019s to groups, call this newly shuffled response $Y^b$.\n",
      "      1. Form the usual $T$ statistic based on response $Y^b$ and store it as $T^b$\n",
      "      1. To test at level $5\\%$, reject $H_0: \\text{difference is 0}$ if $ |T| > . $"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Nonparametric inference\n",
      "\n",
      "* STATS208 is a course on the bootstrap.\n",
      "* Likely covers some other nonparametric inference as well \u2026\n",
      "* STATS205 is a course on nonparametric inference (not offered this year)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Time series / spatial statistics\n",
      "\n",
      "* We just scratched the surface on time series model in our $AR(1)$ example.\n",
      "* STATS207 is an entire course on time series.\n",
      "* STATS252 is an entire course on spatial covariance models (not offered this year)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}